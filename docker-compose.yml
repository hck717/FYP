version: '3.8'

x-airflow-common:
  &airflow-common
  build:
    context: ./docker
    dockerfile: airflow.Dockerfile
  environment:
    &airflow-common-env
    # Airflow Core (from .env)
    AIRFLOW__CORE__EXECUTOR: ${AIRFLOW__CORE__EXECUTOR}
    AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: ${AIRFLOW__DATABASE__SQL_ALCHEMY_CONN}
    AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION: ${AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION}
    AIRFLOW__CORE__LOAD_EXAMPLES: ${AIRFLOW__CORE__LOAD_EXAMPLES}
    AIRFLOW__CORE__ENABLE_XCOM_PICKLING: ${AIRFLOW__CORE__ENABLE_XCOM_PICKLING}
    AIRFLOW__WEBSERVER__SECRET_KEY: ${AIRFLOW__WEBSERVER__SECRET_KEY}
    AIRFLOW_UID: ${AIRFLOW_UID}

    # API Keys (from .env) - Passed to DAGs
    FMP_API_KEY: ${FMP_API_KEY}
    EODHD_API_KEY: ${EODHD_API_KEY}
    FRED_API_KEY: ${FRED_API_KEY}
    REDDIT_CLIENT_ID: ${REDDIT_CLIENT_ID}
    REDDIT_CLIENT_SECRET: ${REDDIT_CLIENT_SECRET}
    REDDIT_USER_AGENT: ${REDDIT_USER_AGENT}

    # Database Connections (from .env)
    POSTGRES_HOST: ${POSTGRES_HOST}
    POSTGRES_PORT: ${POSTGRES_PORT}
    POSTGRES_USER: ${POSTGRES_USER}
    POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
    POSTGRES_DB: ${POSTGRES_DB}
    QDRANT_HOST: ${QDRANT_HOST}
    QDRANT_PORT: ${QDRANT_PORT}
    QDRANT_COLLECTION_NAME: ${QDRANT_COLLECTION_NAME}
    NEO4J_URI: ${NEO4J_URI}
    NEO4J_USER: ${NEO4J_USER}
    NEO4J_PASSWORD: ${NEO4J_PASSWORD}
    NEO4J_HOST: ${NEO4J_HOST}
    NEO4J_PORT: ${NEO4J_PORT}

    # LLM Configuration (from .env) - Passed to DAGs
    OLLAMA_BASE_URL: ${OLLAMA_BASE_URL}
    OLLAMA_HOST: ${OLLAMA_HOST}
    OLLAMA_PORT: ${OLLAMA_PORT}
    LLM_MODEL_BUSINESS_ANALYST: ${LLM_MODEL_BUSINESS_ANALYST}
    LLM_MODEL_QUANTITATIVE: ${LLM_MODEL_QUANTITATIVE}
    LLM_MODEL_FINANCIAL_MODELING: ${LLM_MODEL_FINANCIAL_MODELING}
    EMBEDDING_MODEL: ${EMBEDDING_MODEL}
    EMBEDDING_DIMENSION: ${EMBEDDING_DIMENSION}

    # Agent Settings (from .env) - Passed to DAGs
    BUSINESS_ANALYST_MAX_CHUNKS: ${BUSINESS_ANALYST_MAX_CHUNKS}
    BUSINESS_ANALYST_CHUNK_SIZE: ${BUSINESS_ANALYST_CHUNK_SIZE}
    BUSINESS_ANALYST_OVERLAP: ${BUSINESS_ANALYST_OVERLAP}
    QUANT_AGENT_SQL_TIMEOUT: ${QUANT_AGENT_SQL_TIMEOUT}
    QUANT_AGENT_VERIFICATION_THRESHOLD: ${QUANT_AGENT_VERIFICATION_THRESHOLD}
    FIN_MODEL_DCF_DISCOUNT_RATE: ${FIN_MODEL_DCF_DISCOUNT_RATE}
    FIN_MODEL_TERMINAL_GROWTH_RATE: ${FIN_MODEL_TERMINAL_GROWTH_RATE}

    # Ingestion Settings (from .env) - Passed to DAGs
    TRACKED_TICKERS: ${TRACKED_TICKERS}
    FMP_RATE_LIMIT: ${FMP_RATE_LIMIT}
    EODHD_RATE_LIMIT: ${EODHD_RATE_LIMIT}
    DATA_RETENTION_DAYS: ${DATA_RETENTION_DAYS}

    # Logging (from .env)
    LOG_LEVEL: ${LOG_LEVEL}
    LOG_FORMAT: ${LOG_FORMAT}

  volumes:
    - ./ingestion/dags:/opt/airflow/dags
    - ./data/logs:/opt/airflow/logs
    - ./ingestion/etl:/opt/airflow/etl
  env_file:
    - .env
  depends_on:
    &airflow-common-depends-on
    postgres:
      condition: service_healthy

services:
  # 1. Vector Database (Qdrant)
  qdrant:
    image: qdrant/qdrant:latest
    container_name: fyp-qdrant
    ports:
      - "6333:6333"
      - "6334:6334"
    volumes:
      - ./data/qdrant_storage:/qdrant/storage
    environment:
      - QDRANT__SERVICE__GRPC_PORT=6334
    restart: always
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:6333/health"]
      interval: 10s
      timeout: 5s
      retries: 5

  # 2. Structured Database (PostgreSQL)
  postgres:
    image: postgres:15
    container_name: fyp-postgres
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
    volumes:
      - ./data/postgres_data:/var/lib/postgresql/data
      - ./docker/init-db.sql:/docker-entrypoint-initdb.d/init-db.sql
    ports:
      - "5432:5432"
    env_file:
      - .env
    healthcheck:
      test: ["CMD", "pg_isready", "-U", "${POSTGRES_USER}"]
      interval: 5s
      retries: 5
    restart: always

  # 3. Graph Database (Neo4j)
  neo4j:
    image: neo4j:5.15-community
    container_name: fyp-neo4j
    ports:
      - "${NEO4J_HTTP_PORT}:7474"
      - "${NEO4J_PORT}:7687"
    environment:
      - NEO4J_AUTH=${NEO4J_USER}/${NEO4J_PASSWORD}
      - NEO4J_server_memory_heap_initial__size=512m
      - NEO4J_server_memory_heap_max__size=2G
      - NEO4J_server_memory_pagecache_size=1G
      - NEO4J_dbms_security_procedures_unrestricted=apoc.*
      - NEO4J_dbms_security_procedures_allowlist=apoc.*
    volumes:
      - ./data/neo4j_data:/data
      - ./data/neo4j_logs:/logs
      - ./data/neo4j_import:/var/lib/neo4j/import
      - ./data/neo4j_plugins:/plugins
    env_file:
      - .env
    restart: always
    healthcheck:
      test: ["CMD-SHELL", "wget --no-verbose --tries=1 --spider http://localhost:7474 || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 5

  # 4. Airflow Webserver
  airflow-webserver:
    <<: *airflow-common
    container_name: fyp-airflow-webserver
    command: webserver
    ports:
      - "8080:8080"
    healthcheck:
      test: ["CMD", "curl", "--fail", "http://localhost:8080/health"]
      interval: 10s
      timeout: 10s
      retries: 5
    restart: always

  # 5. Airflow Scheduler
  airflow-scheduler:
    <<: *airflow-common
    container_name: fyp-airflow-scheduler
    command: scheduler
    restart: always

  # 6. Airflow Initialization
  airflow-init:
    <<: *airflow-common
    container_name: fyp-airflow-init
    entrypoint: /bin/bash
    command:
      - -c
      - |
        mkdir -p /opt/airflow/logs /opt/airflow/dags /opt/airflow/etl
        airflow db upgrade
        airflow users create           --username ${AIRFLOW_WWW_USER_USERNAME}           --password ${AIRFLOW_WWW_USER_PASSWORD}           --firstname Admin           --lastname User           --role Admin           --email admin@example.com || true
    environment:
      <<: *airflow-common-env
    depends_on:
      postgres:
        condition: service_healthy
    restart: "no"

networks:
  default:
    name: agentic-analyst-network
